---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Kush Patel, ksp946

### Introduction 


```{R}
library(tidyverse)
library(DAAG)
car_data <- as.data.frame(nassCDS)
tidycar <- car_data %>% select(-caseid, -abcat) %>% filter(occRole == "driver") %>% na.omit()
set.seed(123)
tidycar <- sample_n(tidycar, 150)
```

*This dataset is called "nassCDS" and it can be found in R under DAAG package. I found this data using following website: https://vincentarelbundock.github.io/Rdatasets/datasets.html . This is data of US police-reparted car crashed in which there is a harmful event, and from which at least one vehicle was towed. This data is collected form 1997-2002. The dataset contains 26217 observations with 15 variables. The variables are "dvcat" which is ordered factor with levels of estimated impact speeds. "weight," observation weights, designed to account for varying sampling probabilities. "dead" factor with levels alive or dead. "airbag" is a factor with levels none and airbag. "seatbelt" with factor levels none and belted. "frontal" is a numeric vector with 0 = non-frontal impact, 1= frontal impact, "ageOFocc" tells age of occupants in years. "yearacc" year of accident. "deploy" is a numeric vector with 0 if an airbag was unavailable or did not deploy, 1 if one or more bags deployed. "injSeverity" a numeric vector with 0-6 rating of injury*

*The data was mostly tidy, I just removed all NAs from dataframe and also remove 'caseid' and 'abcat' variables as they are mostly not in use for the project. I also filtered to where data include just the driver who were injured, reduring other variables. Lastly since it was a huge dataset, I have randomly selected 150 observation for the rest of the project. *


### Cluster Analysis

```{R}
library(cluster)
# selecting number of cluster
tidycar%>%ggplot()+geom_point(aes(ageOFocc, yearVeh))

wss<-vector()
for(i in 1:10){
temp<- tidycar %>% select(yearVeh,ageOFocc) %>% kmeans(i)
wss[i]<-temp$tot.withinss
}
ggplot()+geom_point(aes(x=1:10,y=wss))+geom_path(aes(x=1:10,y=wss))+
  xlab("clusters")+scale_x_continuous(breaks=1:10)

# computing silhouette 
clust_dat<-tidycar%>%dplyr::select(yearVeh,ageOFocc)

sil_width<-vector() 
for(i in 2:10){
  kms <- kmeans(clust_dat,centers=i) #compute k-means solution for each k
  sil <- silhouette(kms$cluster,dist(clust_dat)) #get sil widths
  sil_width[i]<-mean(sil[,3]) #take averages (higher is better)
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)
```

*Initially by looking at scatter plot, there is no visible pattern between clusters of "ageOFocc" and "yearVeh", I also chose these two dataset as I wanted to know if year of vehical a person drives is connected to the age of person when the accident occurred. The wss plot shows that the number of clusters which will be appropriate for this data is 2. By computing silhouette width, it shows the same pattern of clusters = 2*
    
```{R}
set.seed(562) 
pam1 <- clust_dat %>% pam(k=2) 
pam1
pamclust<-clust_dat %>% mutate(cluster=as.factor(pam1$clustering))
pamclust %>% ggplot(aes(ageOFocc, yearVeh,color=cluster)) + geom_point()

 pam1$silinfo$avg.width
  plot(pam1,which=2)
```

*By running pam analysis, I found that the average year of vehicle for cluster 1 is 1994 and the average age of accident is 26 for cluster1. I also found that the average year of vehicle for cluster 2 is 1996 and the average age of accident is 55 for cluster2. After plotting colored graph the difference between two cluster is clearly seen. The average Silhouette width is 0.52. Silhouette width between 0.51-0.70 means that a reasonable structure has been found. Silhouette width between 0.26-0.50 means that the structure is weak and could be artificial*

```{R}
#clustering with 3 or more variable 

final <- tidycar %>% select(ageOFocc, yearVeh, deploy, injSeverity) %>% 
    as.data.frame()
pam2 <- final %>% pam(2)
pam2

final <- final %>% mutate(cluster = as.factor(pam2$clustering))
ggplot(final, aes(x = ageOFocc, y = yearVeh, color = cluster)) + 
    geom_point()

library(GGally)
ggpairs(final, aes(color=cluster))
```

*I included another variable, "injSeverity" to plot a 3D graph which shows in detail the difference between these two cluster and relationship between 3 variables. Then I performed PAM clustering with 4 numeric variables. The variables that had highest correlation was "deploy" and "yearVeh", as there is a greater chance that the vehicle have airbag and it will deploy if the vehical is modern compared to older version of vehicle*

### Dimensionality Reduction with PCA

```{R}
# PCA code here
var1 <- tidycar %>% select(frontal, ageOFocc, yearVeh, deploy, injSeverity) %>% as.data.frame()
var1 <- data.frame(scale(var1)) #scaling data


pca1 <- prcomp(var1, center = T, scale = T)
summary(pca1)
eig1 <- var1 %>% cor %>% eigen()
eig1 # eigen value and eigen vectors
var1 %>% cor #correlation matrix
```

*The sd of PC1 is 1.2348 with variance of 0.315, whereas sd of PC2 is 1.0398 with variance of 0.217. Also noticed a trend where as PCs increases, the sd and variance is decreasing. The eigenvalue of PC1 is 1.652 and eigenvalue of PC2 is 1.066.*

```{R}
# How many PCs to keep?
car_pca<-princomp(var1)
eigval<- car_pca$sdev^2 
varprop=round(eigval/sum(eigval), 2) 

ggplot() + geom_bar(aes(y = varprop, x = 1:5), stat = "identity") + 
    xlab("") + geom_path(aes(y = varprop, x = 1:5)) + geom_text(aes(x = 1:5, 
    y = varprop, label = round(varprop, 2)), vjust = 1, col = "white", 
    size = 5) + scale_y_continuous(breaks = seq(0, 0.6, 0.2), 
    labels = scales::percent) + scale_x_continuous(breaks = 1:10)

round(cumsum(eigval)/sum(eigval), 2)
eigval

cardf<-data.frame( PC1=car_pca$scores[, 1],PC2=car_pca$scores[, 2])
ggplot(cardf, aes(PC1, PC2)) + geom_point()


car_pca$scores[, 1:5] %>% as.data.frame %>% top_n(-3, Comp.1) #top 3 lowest PC1
car_pca$scores[, 1:5] %>% as.data.frame %>% top_n(3, Comp.1) #top 3 highest PC1
car_pca$scores[, 1:5] %>% as.data.frame %>% top_n(3, wt = desc(Comp.2)) #top 3 lowest PC2
car_pca$scores[, 1:3] %>% as.data.frame %>% top_n(3, wt = Comp.2) #top 3 highest PC2


```
*Rule of thumb for picking PCs is to pick PCs until cumulative proportion of variance is > 80%. I have also summarize top annd bottom 3 PC1 and PC2. After plotting the scatter graph of PC1 vs PC2, the points looks like they average in a straight horizontal line (as expected)*

###  Linear Classifier

```{R}
y<-tidycar$airbag
x<-tidycar$ageOFocc

y_hat <- sample(c("airbag","none"), size=length(y), replace=T)
tidycar %>% select(ageOFocc, airbag) %>% mutate(predict=y_hat) %>% head
mean(y==y_hat) 

ggplot(data.frame(x,y), aes(x))+geom_density(aes(fill=y), alpha=.5)
ggplot(data.frame(x,y_hat), aes(x))+geom_density(aes(fill=y_hat), alpha=.5) 
 
#confusion matrix 
table(actual=y, predicted = y_hat) %>% addmargins


actual <- c("problem", rep("no problem", 999))
predicted <- rep("no problem", 1000)
TPR <- mean(predicted[actual=="problem"]=="problem")
TNR <- mean(predicted[actual=="no problem"]=="no problem")
(TPR+TNR)/2

#F1 score 
F1 <- function(y, y_hat, positive){
  sensitivity <- mean(y_hat[y==positive]==positive)
  precision <- mean(y[y_hat==positive]==positive)
  2*(sensitivity*precision)/(sensitivity+precision)
}
F1(y, y_hat, "airbag")

n_distinct(tidycar$ageOFocc)
F1score <- vector()
cutoff <- 1:52
for(i in cutoff){
  y_hat <- ifelse(x>i, "airbag", "none")
  F1score[i] <- F1(y_hat,y,"airbag")
}
qplot(y=F1score)+geom_line()+scale_x_continuous(breaks=1:52)

```
*While observing the density graph of "airbag" variable, there is no visible difference between age of accident and airbag. There is jsut slight pattern towards the end where after age of 70, airbags decreases and none increases, maybe because older people are using old car which doesn't equip with airbags. Graph of y_hat is random. The confusion matrix tabulate actual vs predicted value of "airbag" variable. The F1 score is 0.52 which means there is no difference between airbag and none when compared with age. So according to the F1 plot, the cutoff should be around 16* 

```{R}
# binary classification 
class_diag(score = x,truth = y, positive = "airbag", cutoff = 16)

#linear classification
fit <- lm(deploy ~ ageOFocc, data=tidycar)
score <- predict(fit)
score %>% round(3)

tidycar%>% mutate(score=score) %>% ggplot(aes(ageOFocc,deploy)) + geom_point(aes(color=score>.5))+
  geom_smooth(method="lm", se=F)+ylim(0,1)+geom_hline(yintercept=.5, lty=2)

#logistic regression
class_diag(score,truth=tidycar$deploy, positive=1)
fit <- glm(deploy ~ ageOFocc, data=tidycar, family="binomial")
score <- predict(fit, type="response")
score %>% round(3)
tidycar%>% mutate(score=score) %>% ggplot(aes(ageOFocc,deploy))+geom_point(aes(color=score>.5))+
  geom_smooth(method="glm", se=F,method.args = list(family = "binomial"))+ylim(0,1)+geom_hline(yintercept=.5, lty=2)


```

```{R}
#predicting a binary variable (response) from ALL of the rest of the numeric variables in your dataset 
num_data <- tidycar %>% select(deploy, ageOFocc, weight, frontal, yearacc, yearVeh, injSeverity)
fit <- glm(deploy ~ ., data=num_data, family="binomial")
score <- predict(fit, type="response")
class_diag(score,tidycar$deploy,positive=1)
```

*The AUC of binary classification is 0.53 which means the model is very bad. The AUC of logistic regression is not good either with 0.51. The lm and glm method graph is not proper (doesn't tell anything) as there is no visible pattern between age and having airbag or none in the car. But the AUC of glm model of all the numeric variable is 0.895 which is much much better then just "ageOFocc" and "airbag".*

### Non-Parametric Classifier

```{R}
library(caret)
knn_fit <- knn3(deploy == 1 ~ ., data = num_data)
y_hat_knn <- predict(knn_fit,num_data)
y_hat_knn
class_diag(y_hat_knn[,2],num_data$deploy, positive=1)

```

```{R}
#k-fold CV
set.seed(312)
k = 10 #choose number of folds
data<-num_data[sample(nrow(num_data)),] #randomly order rows
folds<-cut(seq(1:nrow(num_data)),breaks=k,labels=F) #create 10 folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$deploy
  ## Train model on training set
  fit<-glm(deploy~.,data=num_data,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
}
summarize_all(diags,mean)

```


```{R}
# k-fold CV with kNN

k=10 #choose number of folds
data<-num_data[sample(nrow(num_data)),] #randomly order rows
folds<-cut(seq(1:nrow(num_data)),breaks=k,labels=F) #create 10 folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$deploy
  ## Train model on training set
  fit<-knn3(deploy~.,data=train)
  probs<-predict(fit,newdata = test)[,2]
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
}
summarize_all(diags,mean)


```

*I predicted the probability of true which means the vehical have airbags, or prob of false, which means beehical does not have airbags or all the 150 observation in the dataset using y_hat and knn fit. The knn analysis AUC is 0.779 which is not bad but it could be better. The AUC of k-fold CV is 0.895 which is very good compared to other AUCs. The AUC of k-fold CV with kNN is 0.547 which is worst then k-fold CV, we can see that doing k-fold with kNN analysis our AUC have gone down drastically.*


### Regression/Numeric Prediction

```{R}
# classification tree 
library(rpart)
library(rpart.plot)
fit<- rpart(deploy~., data=num_data)
rpart.plot(fit)
fit <- train(deploy~., data=num_data, method="rpart")
fit$bestTune
rpart.plot(fit$finalModel)
num_data %>% ggplot(aes(ageOFocc,yearVeh)) +geom_jitter(aes(color=deploy))
```

```{R}
fit<-lm(deploy~.,data=num_data) #predict deploy from all other variables
yhat<-predict(fit) #predicted deploy
mean((num_data$deploy-yhat)^2) #mean squared error (MSE)

#cross validation with kNN Regression

set.seed(1234)
k=5 #choose number of folds
data<-num_data %>% sample_frac() #randomly order rows
folds<-cut(seq(1:nrow(num_data)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  ## Fit linear regression model to training set
  fit<-knnreg(deploy~.,data=train)
  ## Get predictions/y-hats on test set (fold i)
  yhat<-predict(fit,newdata=test)
  ## Compute prediction error  (MSE) for fold i
  diags<-mean((test$deploy-yhat)^2)
}
mean(diags) 

```

*I produced classification tree for the numeric variable in the dataset. It gives the probability of occurrence if the value of variable is true. And the total probability all the end adds up to 1. The cp of the fit is 0.187. Next, I plotter scatter plot of ageOFacc vs. yearVeh with color of deploy. The graph tells that majority of airbags are deployed if the vehicle's year is 1995 or newer. The MSE of data is 0.144. The mean diags of cross validation with kNN regression is 0.209, which is greater than MSE which means our model is doing well.*

### Python 

```{R}
library(reticulate)
use_python("/usr/bin/python3", required = F)
py_install("pandas")
```

```{python, error=TRUE, inlcude=TRUE}
import pandas as pd
pd.set_option('display.max_columns', None)

ca = r.tidycar
ca.head()


filter_data = (ca.filter(['airbag', 'injSeverity'])
 .query('airbag == "airbag"').head(10))
filter_data
#filtering in python
```



```{R}
# converting python dataset again to R 
py$filter_data
```

*For python chuck of code in R-markdown, I install pandas and reticulate package. I converted R dataset to python using r. and filtered the data using .filter function. Then I also converted python dataset to R dataset using py$*


### Concluding Remarks

*This was very interesting data to work to as it had many valuable variables. Overall I saw the trend that for scatter plot of "ageOFocc" vs "vearVeh" variables, there is two possible clusters. Although the linear classifier for "airbag" variable was not predictable (no trend seen), by using all numeric variable, I still got good AUC of 0.89 compared to other AUCs in this project. Lastly it was very interesting to see python and R working side by side as each of them have their own benefits and drawbacks.*




